{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK8u_aGl2sVW"
      },
      "source": [
        "# Coursework 1 - Mathematics for Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiWQAg9V2sVY"
      },
      "source": [
        "## CID: insert your CID here\n",
        "\n",
        "**Colab link:** insert colab link here\n",
        "\n",
        "***\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YIqCr232sVZ"
      },
      "source": [
        "## Part 1: Quickfire questions [3 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbbcTvYZ2sVZ"
      },
      "source": [
        "#### Question 1 (True risk / Empirical risk):\n",
        "\n",
        "Enter your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aEJdGev2sVZ"
      },
      "source": [
        "#### Question 2 ('Large' or 'rich' hypothesis class):\n",
        "\n",
        "Enter your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZcTQdB92sVZ"
      },
      "source": [
        "#### Question 3 (Dataset splitting):\n",
        "\n",
        "Enter your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHjZ21qA2sVZ"
      },
      "source": [
        "#### Question 4 (Occamâ€™s razor):\n",
        "\n",
        "Enter your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyVskoM22sVa"
      },
      "source": [
        "#### Question 5 (Generalisation error):\n",
        "\n",
        "Enter your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Quzf--OL2sVa"
      },
      "source": [
        "#### Question 6 (Rademacher complexity pt1):\n",
        "\n",
        "Enter your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc414RJV2sVa"
      },
      "source": [
        "#### Question 7 (Rademacher complexity pt2):\n",
        "\n",
        "Enter your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY3o2MXl2sVa"
      },
      "source": [
        "#### Question 8 (Regularisation term in the loss function):\n",
        "\n",
        "Enter your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72DlajIW2sVb"
      },
      "source": [
        "#### Question 9 (Momentum gradient descent):\n",
        "\n",
        "Enter your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCwc9wkR2sVb"
      },
      "source": [
        "#### Question 10 (Adam):\n",
        "\n",
        "Enter your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXIZAndw2sVb"
      },
      "source": [
        "#### Question 11 (AdaGrad):\n",
        "\n",
        "Enter your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_k_g_qr2sVb"
      },
      "source": [
        "#### Question 12 (Decaying Learning Rate):\n",
        "\n",
        "Enter your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41dGi5wo2sVb"
      },
      "source": [
        "***\n",
        "***\n",
        "\n",
        "## Part 2: Short-ish proofs [6 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1zlbVwj2sVb"
      },
      "source": [
        "\n",
        "### Question 2.1: Bounds on the risk [1 point]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FDSxbRA2sVb"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp_Kr9T32sVb"
      },
      "source": [
        "***\n",
        "\n",
        "### Question 2.2: On semi-definiteness [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2VWR9iQ2sVb"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4p6Fcyy2sVb"
      },
      "source": [
        "***\n",
        "\n",
        "### Question 2.3: A quick recap of momentum [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1VFKHuZ2sVb"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwuPSbvP2sVc"
      },
      "source": [
        "***\n",
        "\n",
        "### Question 2.4: Convergence proof [3 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqNGw6ku2sVc"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV-W82HD2sVc"
      },
      "source": [
        "***\n",
        "***\n",
        "\n",
        "## Part 3: A deeper dive into neural network implementations [3 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qT6HJlNL2sVc"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uogO3SpP2sVc",
        "outputId": "f584ae90-5dfd-4784-f100-9410a12f2ebe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Download datasets\n",
        "train_set_mnist = torchvision.datasets.MNIST(root=\"./data\", download=True,\n",
        "                                         train=True, transform=transforms.Compose([transforms.ToTensor()]));\n",
        "\n",
        "test_set_mnist = torchvision.datasets.MNIST(root=\"./data\",download=True,\n",
        "                                        train=False,transform=transforms.Compose([transforms.ToTensor()]),);\n",
        "\n",
        "train_set_cifar = torchvision.datasets.CIFAR10(root=\"./data\", download=True,\n",
        "                                         train=True, transform=transforms.Compose([transforms.ToTensor()]));\n",
        "\n",
        "test_set_cifar = torchvision.datasets.CIFAR10(root=\"./data\",download=True,\n",
        "                                        train=False,transform=transforms.Compose([transforms.ToTensor()]),);\n",
        "\n",
        "# Normalizing data:\n",
        "train_set_mnist.data = nn.functional.normalize(train_set_mnist.data.to(float), p=1)\n",
        "test_set_mnist.data = nn.functional.normalize(test_set_mnist.data.to(float), p=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "        A PyTorch Dataset class for loading and normalizing MNIST or CIFAR datasets.\n",
        "        This class preprocesses the data in the following way:\n",
        "        * Choosing the correct trainset or testset.\n",
        "        \n",
        "        * Converting the targets from integers to arrays with length nclass \n",
        "          s.t. the all of the components are zero except the target componenet which is one.\n",
        "          e.g. for raw_target=4, target=[0, 0, 0, 0, 1, 0, 0, 0, 0, 0].\n",
        "        \n",
        "        * Casting the data and targets to torch.float32 (prevents future problems)  \n",
        "\n",
        "        * If normalize=True, normalizes the dataset by the p1 norm.\n",
        "        \n",
        "        Args:\n",
        "            dataset_type (str): Type of dataset, either \"mnist\" or \"cifar\".\n",
        "            train (bool): If True, load the training set; otherwise, load the test set.\n",
        "            normalize (bool): If True, normalize the data.\n",
        "            nclasses (int): Number of classes in the dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset_type, train: bool, normalize: bool, nclasses=10):\n",
        "        match (dataset_type, train):\n",
        "            case (\"mnist\", True):\n",
        "                self.data =  train_set_mnist.data\n",
        "                raw_targets = train_set_mnist.targets\n",
        "                \n",
        "            case (\"mnist\", False):\n",
        "                self.data =  test_set_mnist.data\n",
        "                raw_targets = test_set_mnist.targets\n",
        "\n",
        "            case (\"cifar\", True):\n",
        "                self.data =  train_set_cifar.data\n",
        "                raw_targets = train_set_cifar.targets\n",
        "                \n",
        "            case (\"cifar\", False):\n",
        "                self.data =  test_set_cifar.data\n",
        "                raw_targets = test_set_cifar.targets\n",
        "\n",
        "            case _:\n",
        "                raise ValueError(\"Dataset must be 'mnist' or 'cifar'\")\n",
        "            \n",
        "        self.targets = torch.zeros(len(raw_targets), nclasses, dtype=torch.float32) \n",
        "        for i, t in enumerate(raw_targets):\n",
        "            self.targets[i, int(t)] = 1.                            # Changing the targets into rows with 0 everywhere except the target\n",
        "\n",
        "        self.data = torch.tensor(self.data, dtype=torch.float32)            # Casting to float to prevent future problems.\n",
        "        \n",
        "        if normalize:                                               \n",
        "            self.data = nn.functional.normalize(self.data, p=1)\n",
        "            \n",
        "\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index], self.targets[index]\n",
        "            \n",
        "def test_dataset():\n",
        "    \"\"\"\n",
        "        Test the ImageDataset class by creating an instance and printing a sample.\n",
        "    \"\"\"\n",
        "    traindata = ImageDataset(\"cifar\", False, True)\n",
        "    print(traindata[10])\n",
        "\n",
        "# Unvomment for test:\n",
        "# test_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***\n",
        "\n",
        "### Part 3.1: Implementations [1 point]\n",
        "\n",
        "#### Task 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QEsK7Qzo2sVd"
      },
      "outputs": [],
      "source": [
        "# Set seed\n",
        "SEED = int('02530622')\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GpBUZ0S2sVd",
        "outputId": "eb397d1d-82be-40b0-e2b5-c743e12a1602"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    \"\"\"\n",
        "      A simple feedforward neural network model.\n",
        "\n",
        "      Args:\n",
        "          dim (tuple): Input dimensions (e.g., (28, 28) for MNIST).\n",
        "          nclass (int): Number of classes in the output.\n",
        "          width (int): Width of the hidden layers.\n",
        "          depth (int): Number of hidden layers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim, nclass, width, depth):\n",
        "      super().__init__()\n",
        "      self.dim = dim\n",
        "      self.nclass = nclass\n",
        "      self.width = width\n",
        "      self.depth = depth\n",
        "      self.input_length = np.prod(dim)\n",
        "\n",
        "      self.flatten = nn.Flatten()\n",
        "      self.linear_in = nn.Linear(self.input_length, width)\n",
        "      self.linear_hidden = nn.Linear(width, width)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.linear_out = nn.Linear(width, nclass)\n",
        "\n",
        "    def forward(self, input):\n",
        "      \"\"\"\n",
        "        Forward pass of the neural network.\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Input tensor. Changing the name to \"x\" for convenience.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: the output of the network for given input.\n",
        "      \"\"\"\n",
        "      \n",
        "      x = input   # Changing to a more convenience name \n",
        "      flat_x = self.flatten(x)\n",
        "      lifted_x = self.linear_in(flat_x)\n",
        "\n",
        "      processed_x = lifted_x\n",
        "      for _ in range(self.depth):\n",
        "        processed_x = self.relu(self.linear_hidden(processed_x))\n",
        "\n",
        "      return self.linear_out(processed_x)\n",
        "\n",
        "def test_net(net=None):\n",
        "  \"\"\"\n",
        "    Test the Net class by creating an instance and making a forward pass with a sample.\n",
        "\n",
        "    Args:\n",
        "        net (Net, optional): A pre-trained Net instance. If None, create a new instance.\n",
        "  \"\"\"\n",
        "\n",
        "  mnist_net = Net((28, 28), 10, 16, 2) if net is None else net\n",
        "  sample_index = np.random.randint(10000)\n",
        "\n",
        "  x = train_set_mnist.data[sample_index, :, :]\n",
        "  x = torch.unsqueeze(x, 0)\n",
        "  print(mnist_net(x), train_set_mnist.targets[sample_index])\n",
        "\n",
        "\n",
        "# test_net()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Tasks 2-5\n",
        "All of these tasks are implemented in the NeuralNetworkTrainer class for convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0h4H6KUOCu2-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nadav7679/projects/maths_machine_learning_2024/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
            "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Train Loss: 2.062 |Test Loss: 2.068 | Test Error: 0.7559\n",
            "Epoch: 2 | Train Loss: 2.02 |Test Loss: 2.027 | Test Error: 0.7338\n",
            "Epoch: 3 | Train Loss: 1.979 |Test Loss: 1.989 | Test Error: 0.7165\n",
            "Epoch: 4 | Train Loss: 1.947 |Test Loss: 1.958 | Test Error: 0.7013\n",
            "Epoch: 5 | Train Loss: 1.93 |Test Loss: 1.943 | Test Error: 0.6995\n",
            "Epoch: 6 | Train Loss: 1.903 |Test Loss: 1.92 | Test Error: 0.6833\n",
            "Epoch: 7 | Train Loss: 1.878 |Test Loss: 1.896 | Test Error: 0.6778\n",
            "Epoch: 8 | Train Loss: 1.874 |Test Loss: 1.891 | Test Error: 0.6776\n",
            "Epoch: 9 | Train Loss: 1.853 |Test Loss: 1.879 | Test Error: 0.6704\n",
            "Epoch: 10 | Train Loss: 1.835 |Test Loss: 1.865 | Test Error: 0.6614\n"
          ]
        }
      ],
      "source": [
        "class NeuralNetworkTrainer():\n",
        "  def __init__(\n",
        "      self,\n",
        "      dataset_type,\n",
        "      width,\n",
        "      depth,\n",
        "      criterion, # Notice we assume that reduction=\"mean\"\n",
        "      optimizer,\n",
        "      batch_size=64,\n",
        "      lr=0.001,\n",
        "      max_epoch=1,\n",
        "      normalize=True\n",
        "      ):\n",
        "    \"\"\"\n",
        "      A high-level class for creating, training, and evaluating neural networks on MNIST or CIFAR datasets.\n",
        "\n",
        "      Args:\n",
        "          dataset_type (str): Type of dataset, either \"mnist\" or \"cifar\". dim is set accordingly.\n",
        "          width (int): Width of the hidden layers in the neural network. Hyperparamater!\n",
        "          depth (int): Number of hidden layers in the neural network. Hyperparamater!\n",
        "          criterion (torch loss function): Loss function for training. Assume the loss uses reduction=\"mean\" !\n",
        "          optimizer (torch.optim.Optimizer): Optimization algorithm for training.\n",
        "          batch_size (int, optional): Batch size for training and testing. Default is 64. Hyperparamater!\n",
        "          lr (float, optional): Learning rate for the optimizer. Default is 0.001. Hyperparamater!\n",
        "          max_epoch (int, optional): Maximum number of training epochs. Default is 1. Hyperparamater!\n",
        "          normalize (bool, optional): If True, normalize the data. Default is True.\n",
        "    \"\"\"\n",
        "\n",
        "    match dataset_type:\n",
        "      case \"mnist\":\n",
        "        dim = (28, 28)\n",
        "        nclass = 10\n",
        "\n",
        "      case \"cifar\":\n",
        "        dim = (32, 32, 3)\n",
        "        nclass = 10\n",
        "\n",
        "      case _:\n",
        "        raise ValueError(\"Dataset must be 'mnist' or 'cifar'\")\n",
        "\n",
        "    self.trainset = ImageDataset(dataset_type, train=True, normalize=normalize)\n",
        "    self.testset = ImageDataset(dataset_type, train=False, normalize=normalize)\n",
        "    self.batch_size = batch_size\n",
        "    self.trainloader, self.testloader = self.loading_data()\n",
        "\n",
        "    self.net = Net(dim, nclass, width, depth)\n",
        "    \n",
        "    self.lr = lr\n",
        "    self.max_epoch = max_epoch\n",
        "    self.optimizer = optimizer(self.net.parameters(), lr=self.lr)\n",
        "    self.criterion = criterion\n",
        "\n",
        "\n",
        "  def loading_data(self): # Notice that all of the required arguments are now attributes!\n",
        "    \"\"\"\n",
        "      Create DataLoader instances for the training and testing datasets.\n",
        "\n",
        "      Returns:\n",
        "          tuple: Tuple containing DataLoader instances for training and testing.\n",
        "    \"\"\"\n",
        "\n",
        "    trainloader = DataLoader(self.trainset, self.batch_size, shuffle=True)\n",
        "    testloader = DataLoader(self.testset, self.batch_size, shuffle=False)\n",
        "\n",
        "    return trainloader, testloader\n",
        "\n",
        "\n",
        "  def train_epoch(self):  # Notice that all of the required arguments are now attributes!\n",
        "    \"\"\"\n",
        "      Perform one training epoch.\n",
        "\n",
        "      Returns:\n",
        "          torch.Tensor: Training loss for the epoch based on given loss function.\n",
        "    \"\"\"\n",
        "\n",
        "    self.net.train()\n",
        "\n",
        "    for X, y in self.trainloader:\n",
        "      y_hat = self.net(X)\n",
        "      local_loss = self.criterion(y_hat, y)\n",
        "\n",
        "      local_loss.backward()\n",
        "      self.optimizer.step()\n",
        "      self.optimizer.zero_grad()\n",
        "\n",
        "    return self.criterion(\n",
        "      self.net(self.trainloader.dataset.data),\n",
        "      self.trainloader.dataset.targets\n",
        "      )\n",
        "      \n",
        "      \n",
        "  def test_epoch(self):\n",
        "    \"\"\"\n",
        "      Perform one testing epoch.\n",
        "      \n",
        "      The error is computed as follows:\n",
        "      torch.max(..., 1)[1] is doing argmax over each row and returns a list if ints, s.t.\n",
        "      each int corresponds to the index that has maximal value in this row.\n",
        "      argmax on a prediction returns the most likely class, argmax on the targets give the target.\n",
        "      So, the number of zeros in the expression argmax(predict) - argmax(target) will give back the\n",
        "      number of succsesful predictions, and the number of nonzero elements will give the errors!\n",
        "      Example (batch=2, nclass=3): \n",
        "      \n",
        "      predictions =     [[0.6, 0.4, 0.,],\n",
        "                        [0.7, 0.2, 0.1,]]\n",
        "                        \n",
        "      targets =     [[1, 0., 0.,],\n",
        "                    [0., 1, 0.,]]\n",
        "                    \n",
        "      argmax(predictions) - argmax(targets) = [0 - 0, 0 - 1] = [0, -1]\n",
        "      => number of errors = numbers of nonzero elements = 1\n",
        "\n",
        "\n",
        "\n",
        "      Returns:\n",
        "          tuple: Tuple containing testing loss and number of classification errors.\n",
        "    \"\"\"\n",
        "\n",
        "    y = self.testloader.dataset.data\n",
        "    targets = self.testloader.dataset.targets\n",
        "    \n",
        "    y_hat = self.net(y)\n",
        "    mean_loss = self.criterion(y_hat, targets) # Asuuming reduction=\"mean\"\n",
        "    \n",
        "    target_class = torch.max(targets, 1)[1]\n",
        "    predicted_class = torch.max(y_hat, 1)[1] # Argmax gives predicted_class\n",
        "    \n",
        "    num_errors = len(torch.nonzero(predicted_class - target_class))\n",
        "    \n",
        "  \n",
        "    return mean_loss, num_errors\n",
        "  \n",
        "  \n",
        "  def train_me(self):\n",
        "    \"\"\"\n",
        "      Train the neural network for  max_epoch and print training and testing statistics.\n",
        "    \"\"\"\n",
        "    samples_len = self.testset.data.shape[0]\n",
        "    for i in range(self.max_epoch):\n",
        "      epoch = i + 1\n",
        "      train_loss = self.train_epoch()\n",
        "      test_loss, test_err = self.test_epoch()\n",
        "      \n",
        "      print(f\"Epoch: {epoch} | Train Loss: {train_loss:.04} |\"\n",
        "            f\"Test Loss: {test_loss:.04} | Test Error: {test_err/samples_len:.04}\")\n",
        "        \n",
        "\n",
        "\n",
        "def test_trainednetwork():\n",
        "  cifar_net = NeuralNetworkTrainer(\n",
        "      dataset_type=\"cifar\",\n",
        "      width=16,\n",
        "      depth=2,\n",
        "      criterion=nn.CrossEntropyLoss(),\n",
        "      optimizer=optim.Adam,\n",
        "      max_epoch=10\n",
        "  )\n",
        "\n",
        "  cifar_net.train_me()\n",
        "\n",
        "# Uncomment for network test\n",
        "test_trainednetwork()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHBQTtwc2sVd"
      },
      "source": [
        "***\n",
        "\n",
        "### Part 3.2: Numerical exploration [2 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvLGvBWj2sVe"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J7sSjFlw2sVe"
      },
      "outputs": [],
      "source": [
        "# You can of course add more cells of both code and markdown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZ3YRvuo2sVe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PftX9KPq2sVn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzaGGVnT2sVn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMDhdlAQ2sVn"
      },
      "source": [
        "***\n",
        "***\n",
        "\n",
        "## Part 4: The link between Neural Networks and Gaussian Processes [8 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyCTq6XN2sVo"
      },
      "source": [
        "### Part 4.1: Proving the relationship between a Gaussian process and a neural network [4 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul5rk0ff2sVo"
      },
      "source": [
        "### Task 1: Proper weight scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NV1eU6d2sVo"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOdoN0OQ2sVo"
      },
      "source": [
        "### Task 2: Derive the GP relation for a single hidden layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoIW9iH_2sVo"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbxrzInZ2sVo"
      },
      "source": [
        "### Task 3: Why in succession"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oRi0kiP2sVo"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBiy5sKA2sVo"
      },
      "source": [
        "### Task 4: Derive the GP relation for multiple hidden layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaIEL1AK2sVo"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNzWgsXt2sVo"
      },
      "source": [
        "***\n",
        "\n",
        "### Part 4.2: Analysing the performance of the Gaussian process and a neural network [4 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unW1bYqJ2sVo"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FppSzjEZ2sVo"
      },
      "outputs": [],
      "source": [
        "# Please use float64 as default dtype for this part of the assignment\n",
        "torch.set_default_dtype(torch.float64)\n",
        "\n",
        "# Another hint: when  computing [ K^L(X,X) + noise^2 Id ]^-1 y and  [ K^L(X,X) + noise^2 Id ]^-1 K^L(X,X*)\n",
        "# You can TRY cholesky solve as it should be p.d. (except case for numerical errors) - maybe you can use try:/except:\n",
        "# You can also try to enforce symmetry in posterior covariance by doing (K + K.t())/2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "z_c3V9YH2sVp"
      },
      "outputs": [],
      "source": [
        "# You can of course add more cells of both code and markdown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj_iVLGm2sVp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
