{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK8u_aGl2sVW"
      },
      "source": [
        "# Coursework 1 - Mathematics for Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiWQAg9V2sVY"
      },
      "source": [
        "## CID: insert your CID here\n",
        "\n",
        "**Colab link:** insert colab link here\n",
        "\n",
        "***\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YIqCr232sVZ"
      },
      "source": [
        "## Part 1: Quickfire questions [3 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbbcTvYZ2sVZ"
      },
      "source": [
        "#### Question 1 (True risk / Empirical risk):\n",
        "\n",
        "Given samples and data distribution $(\\textbf{x}, \\textbf{y}) \\sim D$, a hypothesis class and function, $f \\in \\hat{\\mathcal{F}}$, where $f:X \\rightarrow Y$ where $X$ is input space and $Y$ is output space, and loss function $L$, the true risk is\n",
        "\n",
        "$$\n",
        "R(f) := \\mathbb{E}_D[L(f(\\textbf{x}), \\textbf{y})]\\,.\n",
        "$$\n",
        "The real risk measures the expected value of the loss function over the sample distribution, hence giving an estimate to how good our model $f$ is.\n",
        "\n",
        "Since $D$ is usually unkown, we resort to computing the empirical risk, using $N$ samples $(\\textbf{x}_i, \\textbf{y}_i)$ that we do posses, \n",
        "\n",
        "$$\n",
        "\\hat{R}(f) := \\frac{1}{N}\\sum_i^N{L(f(\\textbf{x}_i), \\textbf{y}_i)}\\, .\n",
        "$$\n",
        "So ideally we would like to find $\\hat{f}$ that minimizes $R$, but since we usually cannot do that, we approximate it using $f^*$ that minimizes $\\hat{R}$. The approximation is a good one if $N$ is large (by LLN), otherwise, the approximations isn't gurenteed to be good!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aEJdGev2sVZ"
      },
      "source": [
        "#### Question 2 ('Large' or 'rich' hypothesis class):\n",
        "\n",
        "The benefit of a rich hypothesis class $\\mathcal{F}$ is that its elements would be able to represent more complex data patterns. As we have a variety of functions to \"choose\" from, we would be able to fit a variety of data patterns. The downside of it is that the generalization error is bounded by the magnitude of the hypothesis class (according to Theorm 4.8, $\\log{|\\mathcal{F}|}$ appears in the numerator of the upper bound under $\\sqrt{.}$). This means that a rich hypothesis class gives a bigger range to the generalization error (that we'd like to minimize).   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZcTQdB92sVZ"
      },
      "source": [
        "#### Question 3 (Dataset splitting):\n",
        "\n",
        "We cannot expect the unseen data error to be the same as the validation error. That is because we choose the model according to the validation data (e.g. tune hyperparameters to minimize validation data), so the model has some degree of correlation with this data. When we introduce unseen, novel data to the model, the model has no correlation at all to the new data, hence the error could be different.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHjZ21qA2sVZ"
      },
      "source": [
        "#### Question 4 (Occam’s razor):\n",
        "\n",
        "<font color='red'>Verify answer</font>\n",
        "\n",
        "Occam's razor states that if there are multiple plausible explanation to a certain result, the simpler one is the most likely. In statistical learning, an overfit model may be seen as a complex explanation compared to a (plausible)standard fit model, hence we should pick the latter. It applies to naturally occuring images as inputs to a model. An overfit model would be able to label an image from its training set, but if we alter the image slightly, it'd probably give an incorrect label. That is a problem because in the natural world, images with the same label can be varied (e.g. a picture of a panda and a slightly noisy picture of a panda). Hence, we should follow Occam's razor and choose the simple model for processing of natural images. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyVskoM22sVa"
      },
      "source": [
        "#### Question 5 (Generalisation error):\n",
        "\n",
        "<font color='red'>Verify gen error. Is there a catch here?</font>\n",
        "\n",
        "The generalization error for a given model $f$ is the difference between $R$ and $\\hat{R}$ as defined an answer 1. Since we usually cannot compute $R$ (absence of $D$), we approximate it as the difference between two empirical errors $\\hat{R}$, when one is taken on train data and the other on test data. In a good model, we want to minimize the generalization error. That would mean that our model would perform well on unseen test data, as we want."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Quzf--OL2sVa"
      },
      "source": [
        "#### Question 6 (Rademacher complexity pt1):\n",
        "\n",
        "Rademacher complexity is a metric that measures the 'richness' of a family of functions $G$, using an average over the best fit of G to random noise. If $\\mathcal{F}$ has high Rademacher complexity, it can fit random noise rather accurately. In turn it means that $\\mathcal{F}$ contains functions that are able to be a good fit for a wide variery of different data patterns. When choosing a hypothesis class, if we know that our data patterns are complex and lack visible structure, we should choose a class with high Rademacher complexity.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc414RJV2sVa"
      },
      "source": [
        "#### Question 7 (Rademacher complexity pt2):\n",
        "\n",
        "<font color='red'>The question before ie and after seems different</font>\n",
        "The downside of $\\mathcal{F}$ dependency in (73) is that bigger $\\mathcal{F}$, with bigger Radamacher complexity, would give a bigger bound for the gen. error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY3o2MXl2sVa"
      },
      "source": [
        "#### Question 8 (Regularisation term in the loss function):\n",
        "\n",
        "A regularisation term in the loss function can aid in avoiding unwanted behaviour in the trained model. It is a way to \"nudge\" the model toward certain desired properties.\n",
        "For example, when doing weight decay, we add the size of parameters $|\\boldsymbol{\\theta}|$ to the loss function to avoid large parameter values. Having small parameters (e.g. small weights) would result in the network being less \"sensitive\" to small input differences, which may be a desired result (robustness). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72DlajIW2sVb"
      },
      "source": [
        "#### Question 9 (Momentum gradient descent):\n",
        "\n",
        "In regular Gradient Descent (GD), we could have difficulty choosing the learning rate where the conditioning number $\\frac{\\lambda_{max}}{\\lambda_{min}}$ is too big. The learning rate, \"descent rate\", would vary widely in different directions: in one direction we might have a big slope and overshoot the optimum, and in another a small slope and we won't reach the optimum!\n",
        "\n",
        "Momentum GD solves this problem by accumulating previous gradient data in the step iteration, i.e. when choosing a new step, previous gradient values are accounted for. This solves the previous problem: if we have slow convergence in one direction the gradiant accumalation would make it faster, if we overshoot on a different direction, the gradients would change sign and the descent would slow down (in that direction).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCwc9wkR2sVb"
      },
      "source": [
        "#### Question 10 (Adam):\n",
        "\n",
        "ADAM is an optimization algorithm that is based on Momentum gradient descent. At it's core is the iteration rule over the model's parameters $\\theta$, where\n",
        "$\\theta_{t+1}$ is updated using normalized expressions of $m_t$ and $v_t$, where:\n",
        "\n",
        "* $m_t$ is accumelating gradiants called $g_t$, as in momentum GD\n",
        "* $v_t$ is accumelating second moment of the gradiants $g_t^2$\n",
        "\n",
        "We see that Adam makes use of the \"momentum\" part of MGD even more so, as it uses the first and second moments of the gradiants. In the previous question we had already seen the effects of the first moment. The second moment accounts for the \"width\" of the gradient, and is sometimes called uncentered variance.\n",
        "Adam uses normalized $v_$ and $m_t$ to counter an initialization bias that was detected.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXIZAndw2sVb"
      },
      "source": [
        "#### Question 11 (AdaGrad):\n",
        "<font color='red'>needs some work</font>\n",
        "\n",
        "AdaGrad is an optimazation algorithm that implements Momentum GD. It uses a diagonal metrix called $G$ in which each element represents the sum of the squared gradiants up to this time point, and divides the gradient by this term (specifically $\\frac{g_t}{\\sqrt{G_{ii}^t + \\epsilon}}$ where $ϵ$ is used to avoid zero division). This method has been found to improve the robustness of Stochastic GD.\n",
        "The drawback of the method is that the learning rate decreases with each iteration, as the denumertor grows (sum of positive elements). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_k_g_qr2sVb"
      },
      "source": [
        "#### Question 12 (Decaying Learning Rate):\n",
        "\n",
        "Decaying learning rate can be useful when seeking the minimum in the loss landscape. In the lanscape (i.e. loss values over $n$-dimensional parameter space), we might have many dips and valleys of diffrent sizes, shapes, and slopes. Our trajectory is seeking the minimum loss value, i.e. descending as much as possible. A big learning rate would be helpful in descending big and wide valleys, as it is making \"big leaps\" in the landscape. But as the trajectory descends, the valleys diameter would grow smaller (we increase the resolution, or zooming in). So a big learning rate would make the trajectory jump over and miss the valley instead of going into it. Decaying the learning rate would make the trajectory take small steps towards the valley, and therefore entering it.\n",
        "\n",
        "We can picture it as throwing a marble to a hole in the ground. If the hole is big and far away, we should make a long throw. If the hole is small and near, we should take a short throw. If there is a small hole inside a big valley, we should first take a long throw into the valley, then a short one into the small hole. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41dGi5wo2sVb"
      },
      "source": [
        "***\n",
        "***\n",
        "\n",
        "## Part 2: Short-ish proofs [6 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1zlbVwj2sVb"
      },
      "source": [
        "\n",
        "### Question 2.1: Bounds on the risk [1 point]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FDSxbRA2sVb"
      },
      "source": [
        "#### (1)\n",
        "Let us reframe our problem in the notation of Hoeffding's Inequality (Theorm 4.2 notes) and then substitute in the inequality.\n",
        "\n",
        "For $S$ training sample and $N$ i.i.d variables $\\{\\textbf{x}\\}_{i=1}^N$ distributed according to $D$\n",
        " (these are r.v. and not samples), we assume deterministic targets $y_i = f(x)$ for some $x$. We also assume that our loss function is $L(f(\\textbf{x}), y)=\\mathbb{1}_{f(\\textbf{x})\\ne y}$ .\n",
        "\n",
        "\n",
        "Now, in the notation of Theorm 4.2, consider the random variables $X_i := L(f(\\textbf{x}_i), y_i)$. They are i.i.d because $\\textbf{x}_i$ are i.i.d and they are bounded between $[a_i,b_i]=[0,1] \\forall i \\le N$.\n",
        "\n",
        "Define $S_N := ∑^N_i{X_i}$ and note that $S_N = N\\hat{R}(f)$. Also note, using linearity of expectation and definition of $\\hat{R}(f)$:\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\mathbb{E}[S_N] = \\mathbb{E} [N\\hat{R}(f)] = ∑_i^N \\mathbb{E}[L(f(\\textbf{x}_i), y_i)] = N \\mathbb{E}[L(f(\\textbf{x}_1), y_1)]=NR(f)\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "Now, as $X_i$ are bounded i.i.d, we can use Hoeffdings Inequality:\n",
        "\n",
        "Choose $\\tilde{ϵ}>0$. Then,\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\mathbb{P}[|S_N - \\mathbb{E}[S_N]| \\ge \\tilde{ϵ}] \\le  \\exp{(-2\\tilde{ϵ}^2/∑_i^N(b_i - a_i)}).\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "Using our definitions and relations, this becomes\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\mathbb{P}[|N\\hat{R}(f) - NR(f)| \\ge \\tilde{ϵ}] \\le  \\exp{(-2\\tilde{ϵ}^2/∑_i^N(1)})=\\exp{\\frac{-2\\tilde{ϵ}^2}{N}}.\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "And since $\\tilde{ϵ}$ is arbitrary, we can choose $\\tilde{ϵ}=Nϵ$ to find:\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\mathbb{P}[|\\hat{R}(f) - R(f)| \\ge ϵ] \\le  \\exp{(-2ϵ^2/∑_i^N(1)})=\\exp{-2N ϵ^2}.\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "Which gives us Corollary 4.6. 🙂\n",
        "\n",
        "\n",
        "*Remark:* the probability and the expectation are taken with respect to our sample $S$ out of the distribution $D^N$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### (2)\n",
        "The interpretation of the result above shows us that the probability of the gen. error to be above or below $ϵ$ (meaning, the \"tails\" of the $pdf$) is decreasing monotoniclly with the sample size $N$. For a fixed $ϵ$, if we take the limit of the sample size $N \\rightarrow \\infty$, then the probability drops to zero, meaning that the tails of the gen. error are bigger than $ϵ$ almost surely.\n",
        "\n",
        "<font color='red'>Unsure if I need all of these details</font>\n",
        "\n",
        "\n",
        "Let us look at the inverse of the result above:\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\mathbb{P}[|\\hat{R}(f) - R(f)| < ϵ] \\le 1 - \\exp{(-2N ϵ^2)}.\n",
        "\\end{equation}\n",
        "$$\n",
        "Now if we fix $N$ and take $ϵ → 0$ then we would find that the probability of the gen. error to be zero is zero!\n",
        "\n",
        "In general, this means that there is a \"fight\" between the sample size $N$ and our bound $ϵ$, only that the bound is quadratic. If we want the gen. error to drop below $ϵ$ (within a given fixed tolerance), then increasing $N$ quadratically would give us the desired bound!    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### (3)\n",
        "The bound in Theorm 4.8 tells us that the gen. error is bounded by the log of the cardinality of the hypothesis class. This means that there is a tradeoff:\n",
        "Choosing a big hypothesis class will allow our model to fit complex data better, but it will also raise the bound, so our gen. error could get bigger.\n",
        "However, the log function ensures that the bound goes up slower then our hypothesis class expands, which is helpful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp_Kr9T32sVb"
      },
      "source": [
        "***\n",
        "\n",
        "### Question 2.2: On semi-definiteness [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2VWR9iQ2sVb"
      },
      "source": [
        "First let us show that $g$ is convex.\n",
        "The derivative of $g$ is\n",
        "$$\n",
        "g'(t) = \\frac{df}{dt} = (\\nabla f) \\frac{d}{dt} (\\boldsymbol{x} + t \\boldsymbol{v}) = \\nabla f ^T \\cdot \\boldsymbol{v} \\; .\n",
        "$$\n",
        "\n",
        "Denote $t_1, t_2$ and $\\boldsymbol{y}_i = \\boldsymbol{x} + t_i \\boldsymbol{v}$, so $g(t_i) = f(\\boldsymbol{y}_i) \\; i=1,2$. Then, using convexity of $f$:\n",
        "\n",
        "$$\n",
        "g(t_1) = f(\\boldsymbol{y}_1) \\ge f(\\boldsymbol{y}_2) + \\nabla f(\\boldsymbol{y}_2)^T \\cdot(\\boldsymbol{y_1 - y_2}) \\\\\n",
        "= g(t_2) +  \\nabla f(\\boldsymbol{y}_2)^T \\cdot \\boldsymbol{v} (t_1 - t_2) \\\\\n",
        "= g(t_2) +  g'(t_2)  (t_1 - t_2) \\; ,\n",
        "$$\n",
        "\n",
        "hence $g$ is convex. This makes sense, as $g$ is just a translation of $f$ in a certain (constant) direction, so the geometry of $f$ remains.\n",
        "\n",
        "Since $g$ is convex, $g''(t) \\ge 0$, which is,\n",
        "\n",
        "$$\n",
        "g''(t) = \\frac{d}{dt} \\nabla f^T \\boldsymbol{v} = \\boldsymbol{v}^T \\cdot \\nabla^2 f \\cdot \\boldsymbol{v} \\ge 0 \\; .\n",
        "$$\n",
        "The last equation is independent of choice of $\\boldsymbol{v}$, hence the Hessian of $f$ is positive semidefinite."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4p6Fcyy2sVb"
      },
      "source": [
        "***\n",
        "\n",
        "### Question 2.3: A quick recap of momentum [1 point]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1VFKHuZ2sVb"
      },
      "source": [
        "#### (1)\n",
        "\n",
        "Using this decomposition, we can identify and work with the \"preffered directions\" of the system, i.e. work in a coordinate system where the coordinates $w_1, ..., w_k$ are aligned with the directions of our objective function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwuPSbvP2sVc"
      },
      "source": [
        "***\n",
        "\n",
        "### Question 2.4: Convergence proof [3 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqNGw6ku2sVc"
      },
      "source": [
        "#### (1)\n",
        "Evolution of Newton's method:\n",
        "\n",
        "$$\n",
        "\\boldsymbol{x}_{k+1} = \\boldsymbol{x}_{k} - \\alpha \\nabla^2 f(\\boldsymbol{x}_{k})^{-1} \\nabla f(\\boldsymbol{x}_{k})\n",
        "$$\n",
        "where $\\alpha$ is the learning rate. We'll take $\\alpha=1$ in the following calculations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### (2)\n",
        "\n",
        "Let us compute the gradiant of $f$:\n",
        "\n",
        "$$\n",
        "\\nabla f(\\boldsymbol{x}) = \\frac{1}{2} \\nabla (\\boldsymbol{x}^T Q \\boldsymbol{x}) + \\nabla(b^T \\boldsymbol{x} + c) = \\frac{1}{2} (\\boldsymbol{x}^T Q)^T + \\frac{1}{2} Q \\boldsymbol{x} + b^T = Q \\boldsymbol{x} + b^T \n",
        "$$\n",
        "\n",
        "where we used the fact that $Q$ is positive definite, hence symmetric. \n",
        "Now the Hessian:\n",
        "\n",
        "$$\n",
        "\\nabla^2 f(\\boldsymbol{x})_{i,j} =  \\frac{1}{2} \\frac{\\partial^2}{\\partial {x_i} \\partial {x_j}} \\sum_{l, k} x_l x_k Q_{lk} = \\frac{1}{2} \\sum_{l, k} (\\delta _{il} \\delta _{jk} + \\delta _{jl} \\delta _{ik}) Q_{lk} = \\frac{1}{2} (Q_{ij} + Q_{ji}) = Q_{ij}\n",
        "$$\n",
        "\n",
        "where in the last step we used symmetry of $Q$ again.\n",
        "Combining this we find:\n",
        "\n",
        "$$\n",
        "\\boldsymbol{x}_{1} = \\boldsymbol{x}_{0} - Q^{-1} (Q \\boldsymbol{x_0} + b^T ) = Q^{-1}b^T\n",
        "$$\n",
        "which leads to\n",
        "\n",
        "$$\n",
        "\\nabla f(x_1) = 0 \\; .\n",
        "$$\n",
        "Note that the hessian is positive at all points ($Q$ is positive definite), therefore $x_1$ is in fact a minimum ($x_1 = x^{*}$). Hence, the method converged to the minimum in a single step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### (3)\n",
        "The method is based on 2nd order Taylor expansion, hence one of the condition is that we can expand the function using 2nd order taylor ($f \\in C^3$). Generally, it means that in a local neighborhood of $x^*$, $f$ looks as if it is quadratic, so 2nd order Taylor can be used to find the minimum. When our function is quadratic as in (2), the Taylor expansion is no longer an approximation, it is exact. Hence the method converges in a single step.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### (4)\n",
        "\n",
        "We can view the Hessian as a matrix valued function in the sense of Lemma 0.2. Then according to the Lemma, since the Hessian is invertible at $\\boldsymbol{x}^*$, there exists $B(\\epsilon, \\boldsymbol{x}^*)$ such that every point in that environment has an invertible Hessian. Let $x_0$ be in that environment, then,\n",
        "\n",
        "$$\n",
        "\\Vert \\boldsymbol{x}_1 - \\boldsymbol{x}^* \\Vert = \\Vert (\\boldsymbol{x}_0 - \\boldsymbol{x}^*) - \\nabla^2 f(\\boldsymbol{x}_{0})^{-1} \\nabla f(\\boldsymbol{x}_{0}) \\Vert \\\\\n",
        "= \\Vert \\nabla^2 f(\\boldsymbol{x}_{0})^{-1} \\left[ \\nabla^2 f(\\boldsymbol{x}_{0}) (\\boldsymbol{x}_0 - \\boldsymbol{x}^*) - \\nabla f(\\boldsymbol{x}_{0}) \\right] \\Vert \\\\\n",
        "\\le \\Vert \\nabla^2 f(\\boldsymbol{x}_{0})^{-1} \\Vert \\Vert \\nabla^2 f(\\boldsymbol{x}_{0}) (\\boldsymbol{x}_0 - \\boldsymbol{x}^*) - \\nabla f(\\boldsymbol{x}_{0}) \\Vert \n",
        "$$\n",
        "where in the last inequality we used Lemma 0.1 and matrix norm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### (5)\n",
        "\n",
        "We will try to bound the expression from (4) (using the Ed hint). First note that, according to Lemma 0.2 as stated before, for $\\boldsymbol{x_0} \\in B(\\epsilon, \\boldsymbol{x^*})$ the Hessian is invertible (and bounded). We can define\n",
        "\n",
        "$$\n",
        "c_1 := \\Vert \\nabla^2 f(\\boldsymbol{x}_{0})^{-1} \\Vert \\; .\n",
        "$$\n",
        "\n",
        "Next, we approximate $\\nabla f$ by Taylor at $x_0$,\n",
        "\n",
        "$$\n",
        "\\nabla f(\\boldsymbol{x}) = \\nabla f(\\boldsymbol{x_0}) + \\nabla^2 f(\\boldsymbol{x - x_0}) + \\mathcal{O} \\left(  (\\boldsymbol{x} - \\boldsymbol{x_0}) ^2 \\right)\n",
        "$$\n",
        "\n",
        "Then, if we isolate the $\\mathcal{O}$ term, and take the norm, we find \n",
        "\n",
        "$$\n",
        "\\Vert \\nabla f(\\boldsymbol{x}) - \\nabla f(\\boldsymbol{x_0}) - \\nabla^2 f(\\boldsymbol{x - x_0}) \\Vert ^2 \\le c_2   \\Vert \\boldsymbol{x} - \\boldsymbol{x_0} \\Vert ^2\n",
        "$$\n",
        "\n",
        "where $c_2>0$ is a constant. We can think of this as the \"error\" of our taylor approximation. Note that this is a bound on the RHS differene in (4). Taking $\\boldsymbol{x} = \\boldsymbol{x}^*$, using $c_1$, and the inequality from (4) results in\n",
        "\n",
        "$$\n",
        "\\Vert \\boldsymbol{x}^* - \\boldsymbol{x}_1 \\Vert \\le c_1 \\Vert - \\nabla f(\\boldsymbol{x_0}) - \\nabla^2 f(\\boldsymbol{x^* - x_0}) \\Vert ^2 \\le c_1c_2   \\Vert \\boldsymbol{x^*} - \\boldsymbol{x_0} \\Vert ^2 \\; ,\n",
        "$$\n",
        "where we used the fact that $\\nabla f(\\boldsymbol{x}^*) = 0$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### (6)\n",
        "We will use the previous result. Again $\\boldsymbol{x_0} \\in B(\\epsilon, \\boldsymbol{x^*})$. The given relation can be written as\n",
        "\n",
        "$$\n",
        "c_1c_2 \\Vert \\boldsymbol{x}^* - \\boldsymbol{x}_0 \\Vert ^2 \\le \\alpha \\Vert \\boldsymbol{x^*} - \\boldsymbol{x_0} \\Vert \\; .\n",
        "$$\n",
        "Then, using (5) and $\\alpha < 1$ we find\n",
        "\n",
        "$$\n",
        "\\Vert \\boldsymbol{x}^* - \\boldsymbol{x}_1 \\Vert \\le c_1c_2 \\Vert \\boldsymbol{x^*} - \\boldsymbol{x_0} \\Vert ^2 \\le \\alpha \\Vert \\boldsymbol{x^*} - \\boldsymbol{x_0} \\Vert \\le \\Vert \\boldsymbol{x^*} - \\boldsymbol{x_0} \\Vert < \\epsilon \\; .\n",
        "$$\n",
        "\n",
        "Instead of $\\epsilon$, we can plug the given relation and get\n",
        "$$\n",
        "\\Vert \\boldsymbol{x}^* - \\boldsymbol{x}_1 \\Vert \\le \\Vert \\boldsymbol{x^*} - \\boldsymbol{x_0} \\Vert \\le \\frac{\\alpha}{c_1c_2}  \\; .\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### (7)\n",
        "Given $\\boldsymbol{x_k} \\in B(\\epsilon, \\boldsymbol{x^*})$ and $\\Vert \\boldsymbol{x^*} - \\boldsymbol{x}_k \\Vert \\le \\frac{\\alpha}{c_1c_2}$, we can repeat the above to find\n",
        "\n",
        "$$\n",
        "\\Vert \\boldsymbol{x}^* - \\boldsymbol{x}_{k+1} \\Vert \\le c_1c_2 \\Vert \\boldsymbol{x^*} - \\boldsymbol{x_k} \\Vert ^2 \\le \\alpha \\Vert \\boldsymbol{x^*} - \\boldsymbol{x}_k \\Vert \\; .\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### (8)\n",
        "Applying (7) in iteration results in\n",
        "\n",
        "$$\n",
        "\\Vert \\boldsymbol{x}^* - \\boldsymbol{x}_{k+1} \\Vert \\le \\alpha \\Vert \\boldsymbol{x^*} - \\boldsymbol{x}_k \\Vert \\le ... \\le \\alpha^k \\Vert \\boldsymbol{x^*} - \\boldsymbol{x}_0 \\Vert < \\epsilon \\; ,\n",
        "$$\n",
        "\n",
        "hence  $\\lim_{k\\to\\infty} \\Vert \\boldsymbol{x}^* - \\boldsymbol{x}_{k+1} \\Vert$ = 0.\n",
        "Note that this is subject to the constraints $0< \\alpha < 1,\\Vert \\boldsymbol{x^*} - \\boldsymbol{x}_k \\Vert \\le \\frac{\\alpha}{c_1c_2}$.\n",
        "\n",
        "The quadratic rate can be seen from applying (5):\n",
        "$$\n",
        "\\Vert \\boldsymbol{x}^* - \\boldsymbol{x}_{k+1} \\Vert \\le c_1c_2   \\Vert \\boldsymbol{x^*} - \\boldsymbol{x}_{k} \\Vert ^2 \\; .\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV-W82HD2sVc"
      },
      "source": [
        "***\n",
        "***\n",
        "\n",
        "## Part 3: A deeper dive into neural network implementations [3 points]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qT6HJlNL2sVc"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KdaTXHrM3iIg"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uogO3SpP2sVc",
        "outputId": "8f0fcf9d-ee8c-4a73-8761-0510791e55a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Download datasets\n",
        "train_set_mnist = torchvision.datasets.MNIST(root=\"./data\", download=True,\n",
        "                                         train=True, transform=transforms.Compose([transforms.ToTensor()]));\n",
        "\n",
        "test_set_mnist = torchvision.datasets.MNIST(root=\"./data\",download=True,\n",
        "                                        train=False,transform=transforms.Compose([transforms.ToTensor()]),);\n",
        "\n",
        "train_set_cifar = torchvision.datasets.CIFAR10(root=\"./data\", download=True,\n",
        "                                         train=True, transform=transforms.Compose([transforms.ToTensor()]));\n",
        "\n",
        "test_set_cifar = torchvision.datasets.CIFAR10(root=\"./data\",download=True,\n",
        "                                        train=False,transform=transforms.Compose([transforms.ToTensor()]),);\n",
        "\n",
        "# Normalizing data:\n",
        "train_set_mnist.data = nn.functional.normalize(train_set_mnist.data.to(float), p=1)\n",
        "test_set_mnist.data = nn.functional.normalize(test_set_mnist.data.to(float), p=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufVhg5gywAbx"
      },
      "source": [
        "#### Data preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Kt1VVk_dwAbx"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "        A PyTorch Dataset class for loading and normalizing MNIST or CIFAR datasets.\n",
        "        This class preprocesses the data in the following way:\n",
        "        * Choosing the correct trainset or testset.\n",
        "\n",
        "        * Converting the targets from integers to arrays with length nclass\n",
        "          s.t. the all of the components are zero except the target componenet which is one.\n",
        "          e.g. for raw_target=4, target=[0, 0, 0, 0, 1, 0, 0, 0, 0, 0].\n",
        "\n",
        "        * Casting the data and targets to torch.float32 (prevents future problems)\n",
        "\n",
        "        * If normalize=True, normalizes the dataset by the p1 norm.\n",
        "\n",
        "        Args:\n",
        "            dataset_type (str): Type of dataset, either \"mnist\" or \"cifar\".\n",
        "            train (bool): If True, load the training set; otherwise, load the test set.\n",
        "            normalize (bool): If True, normalize the data.\n",
        "            nclasses (int): Number of classes in the dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset_type, train: bool, normalize: bool, nclasses=10):\n",
        "        match (dataset_type, train):\n",
        "            case (\"mnist\", True):\n",
        "                self.data =  train_set_mnist.data\n",
        "                raw_targets = train_set_mnist.targets\n",
        "\n",
        "            case (\"mnist\", False):\n",
        "                self.data =  test_set_mnist.data\n",
        "                raw_targets = test_set_mnist.targets\n",
        "\n",
        "            case (\"cifar\", True):\n",
        "                self.data =  train_set_cifar.data\n",
        "                raw_targets = train_set_cifar.targets\n",
        "\n",
        "            case (\"cifar\", False):\n",
        "                self.data =  test_set_cifar.data\n",
        "                raw_targets = test_set_cifar.targets\n",
        "\n",
        "            case _:\n",
        "                raise ValueError(\"Dataset must be 'mnist' or 'cifar'\")\n",
        "\n",
        "\n",
        "        self._create_data(raw_targets)\n",
        "        self._create_targets(raw_targets, nclasses)\n",
        "\n",
        "        if normalize:\n",
        "            self.data = nn.functional.normalize(self.data, p=1)\n",
        "\n",
        "        self.targets = self.targets.to(device=device)\n",
        "        self.data = self.data.to(device=device)\n",
        "\n",
        "    def _create_data(self, raw_targets):\n",
        "      self.data = torch.tensor(self.data, dtype=torch.float32)\n",
        "\n",
        "\n",
        "    def _create_targets(self, raw_targets, nclasses):\n",
        "      \"\"\"\n",
        "      A function that gets the raw_targets (labels) and manipulates them to new\n",
        "      targets.\n",
        "      \"\"\"\n",
        "      self.targets = torch.zeros(len(raw_targets), nclasses, dtype=torch.float32)\n",
        "      for i, t in enumerate(raw_targets):\n",
        "          self.targets[i, int(t)] = 1.                            # Changing the targets into rows with 0 everywhere except the target\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index], self.targets[index]\n",
        "\n",
        "def test_dataset():\n",
        "    \"\"\"\n",
        "        Test the ImageDataset class by creating an instance and printing a sample.\n",
        "    \"\"\"\n",
        "    traindata = ImageDataset(\"cifar\", False, True)\n",
        "    print(traindata[10])\n",
        "\n",
        "# Unvomment for test:\n",
        "# test_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtK6tqwqwAbz"
      },
      "source": [
        "***\n",
        "\n",
        "### Part 3.1: Implementations [1 point]\n",
        "\n",
        "#### Task 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QEsK7Qzo2sVd"
      },
      "outputs": [],
      "source": [
        "# Set seed\n",
        "SEED = int('02530622')\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1GpBUZ0S2sVd"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    \"\"\"\n",
        "      A simple feedforward neural network model.\n",
        "\n",
        "      Args:\n",
        "          dim (tuple): Input dimensions (e.g., (28, 28) for MNIST).\n",
        "          nclass (int): Number of classes in the output.\n",
        "          width (int): Width of the hidden layers.\n",
        "          depth (int): Number of hidden layers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim, nclass, width, depth):\n",
        "      super().__init__()\n",
        "      self.dim = dim\n",
        "      self.nclass = nclass\n",
        "      self.width = width\n",
        "      self.depth = depth\n",
        "      self.input_length = np.prod(dim)\n",
        "\n",
        "      self.flatten = nn.Flatten()\n",
        "      self.linear_in = nn.Linear(self.input_length, width, device=device)\n",
        "      self.linear_hidden = nn.Linear(width, width, device=device)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.linear_out = nn.Linear(width, nclass, device=device)\n",
        "\n",
        "    def forward(self, input):\n",
        "      \"\"\"\n",
        "        Forward pass of the neural network.\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Input tensor. Changing the name to \"x\" for convenience.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: the output of the network for given input.\n",
        "      \"\"\"\n",
        "\n",
        "      x = input   # Changing to a more convenience name\n",
        "      flat_x = self.flatten(x)\n",
        "      lifted_x = self.linear_in(flat_x)\n",
        "\n",
        "      processed_x = lifted_x\n",
        "      for _ in range(self.depth):\n",
        "        processed_x = self.relu(self.linear_hidden(processed_x))\n",
        "\n",
        "      return self.linear_out(processed_x)\n",
        "\n",
        "def test_net(net=None):\n",
        "  \"\"\"\n",
        "    Test the Net class by creating an instance and making a forward pass with a sample.\n",
        "\n",
        "    Args:\n",
        "        net (Net, optional): A pre-trained Net instance. If None, create a new instance.\n",
        "  \"\"\"\n",
        "\n",
        "  mnist_net = Net((28, 28), 10, 16, 2) if net is None else net\n",
        "  sample_index = np.random.randint(10000)\n",
        "\n",
        "  x = train_set_mnist.data[sample_index, :, :]\n",
        "  x = torch.unsqueeze(x, 0)\n",
        "  print(mnist_net(x), train_set_mnist.targets[sample_index])\n",
        "\n",
        "\n",
        "# test_net()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YM42iN5wAb0"
      },
      "source": [
        "#### Tasks 2-5\n",
        "All of these tasks are implemented in the NeuralNetworkTrainer class for convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h4H6KUOCu2-",
        "outputId": "63adf1dc-96b8-47f9-866d-2215f288f516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Train Loss: 2.094 |Test Loss: 2.097 | Test Error: 0.7635\n",
            "Epoch: 2 | Train Loss: 2.022 |Test Loss: 2.03 | Test Error: 0.7348\n",
            "Epoch: 3 | Train Loss: 1.996 |Test Loss: 2.006 | Test Error: 0.7255\n",
            "Epoch: 4 | Train Loss: 1.963 |Test Loss: 1.973 | Test Error: 0.7053\n",
            "Epoch: 5 | Train Loss: 1.925 |Test Loss: 1.937 | Test Error: 0.6896\n",
            "Epoch: 6 | Train Loss: 1.897 |Test Loss: 1.912 | Test Error: 0.6791\n",
            "Epoch: 7 | Train Loss: 1.881 |Test Loss: 1.896 | Test Error: 0.673\n",
            "Epoch: 8 | Train Loss: 1.87 |Test Loss: 1.89 | Test Error: 0.674\n",
            "Epoch: 9 | Train Loss: 1.846 |Test Loss: 1.866 | Test Error: 0.6653\n",
            "Epoch: 10 | Train Loss: 1.839 |Test Loss: 1.862 | Test Error: 0.666\n"
          ]
        }
      ],
      "source": [
        "class NeuralNetworkTrainer():\n",
        "  def __init__(\n",
        "      self,\n",
        "      dataset_type,\n",
        "      width,\n",
        "      depth,\n",
        "      criterion, # Notice we assume that reduction=\"mean\"\n",
        "      optimizer,\n",
        "      batch_size=64,\n",
        "      lr=0.001,\n",
        "      max_epoch=1,\n",
        "      normalize=True\n",
        "      ):\n",
        "    \"\"\"\n",
        "      A high-level class for creating, training, and evaluating neural networks on MNIST or CIFAR datasets.\n",
        "\n",
        "      Args:\n",
        "          dataset_type (str): Type of dataset, either \"mnist\" or \"cifar\". dim is set accordingly.\n",
        "          width (int): Width of the hidden layers in the neural network. Hyperparamater!\n",
        "          depth (int): Number of hidden layers in the neural network. Hyperparamater!\n",
        "          criterion (torch loss function): Loss function for training. Assume the loss uses reduction=\"mean\" !\n",
        "          optimizer (torch.optim.Optimizer): Optimization algorithm for training.\n",
        "          batch_size (int, optional): Batch size for training and testing. Default is 64. Hyperparamater!\n",
        "          lr (float, optional): Learning rate for the optimizer. Default is 0.001. Hyperparamater!\n",
        "          max_epoch (int, optional): Maximum number of training epochs. Default is 1. Hyperparamater!\n",
        "          normalize (bool, optional): If True, normalize the data. Default is True.\n",
        "    \"\"\"\n",
        "\n",
        "    match dataset_type:\n",
        "      case \"mnist\":\n",
        "        dim = (28, 28)\n",
        "        nclass = 10\n",
        "\n",
        "      case \"cifar\":\n",
        "        dim = (32, 32, 3)\n",
        "        nclass = 10\n",
        "\n",
        "      case _:\n",
        "        raise ValueError(\"Dataset must be 'mnist' or 'cifar'\")\n",
        "\n",
        "    self.trainset = ImageDataset(dataset_type, train=True, normalize=normalize)\n",
        "    self.testset = ImageDataset(dataset_type, train=False, normalize=normalize)\n",
        "    self.batch_size = batch_size\n",
        "    self.trainloader, self.testloader = self.loading_data()\n",
        "\n",
        "    self.net = Net(dim, nclass, width, depth)\n",
        "\n",
        "    self.lr = lr\n",
        "    self.max_epoch = max_epoch\n",
        "    self.optimizer = optimizer(self.net.parameters(), lr=self.lr)\n",
        "    self.criterion = criterion\n",
        "\n",
        "\n",
        "  def loading_data(self): # Notice that all of the required arguments are now attributes!\n",
        "    \"\"\"\n",
        "      Create DataLoader instances for the training and testing datasets.\n",
        "\n",
        "      Returns:\n",
        "          tuple: Tuple containing DataLoader instances for training and testing.\n",
        "    \"\"\"\n",
        "\n",
        "    trainloader = DataLoader(self.trainset, self.batch_size, shuffle=True)\n",
        "    testloader = DataLoader(self.testset, self.batch_size, shuffle=False)\n",
        "\n",
        "    return trainloader, testloader\n",
        "\n",
        "\n",
        "  def train_epoch(self):  # Notice that all of the required arguments are now attributes!\n",
        "    \"\"\"\n",
        "      Perform one training epoch.\n",
        "\n",
        "      Returns:\n",
        "          torch.Tensor: Training loss for the epoch based on given loss function.\n",
        "    \"\"\"\n",
        "\n",
        "    self.net.train()\n",
        "\n",
        "    for X, y in self.trainloader:\n",
        "      y_hat = self.net(X)\n",
        "      local_loss = self.criterion(y_hat, y)\n",
        "\n",
        "      local_loss.backward()\n",
        "      self.optimizer.step()\n",
        "      self.optimizer.zero_grad()\n",
        "\n",
        "    return self.criterion(\n",
        "      self.net(self.trainloader.dataset.data),\n",
        "      self.trainloader.dataset.targets\n",
        "      )\n",
        "\n",
        "\n",
        "  def test_epoch(self):\n",
        "    \"\"\"\n",
        "      Perform one testing epoch.\n",
        "\n",
        "      The error is computed as follows:\n",
        "      torch.max(..., 1)[1] is doing argmax over each row and returns a list if ints, s.t.\n",
        "      each int corresponds to the index that has maximal value in this row.\n",
        "      argmax on a prediction returns the most likely class, argmax on the targets give the target.\n",
        "      So, the number of zeros in the expression argmax(predict) - argmax(target) will give back the\n",
        "      number of succsesful predictions, and the number of nonzero elements will give the errors!\n",
        "      Example (batch=2, nclass=3):\n",
        "\n",
        "      predictions =     [[0.6, 0.4, 0.,],\n",
        "                        [0.7, 0.2, 0.1,]]\n",
        "\n",
        "      targets =     [[1, 0., 0.,],\n",
        "                    [0., 1, 0.,]]\n",
        "\n",
        "      argmax(predictions) - argmax(targets) = [0 - 0, 0 - 1] = [0, -1]\n",
        "      => number of errors = numbers of nonzero elements = 1\n",
        "\n",
        "\n",
        "\n",
        "      Returns:\n",
        "          tuple: Tuple containing testing loss and number of classification errors.\n",
        "    \"\"\"\n",
        "    self.net.eval()\n",
        "    y = self.testloader.dataset.data\n",
        "    targets = self.testloader.dataset.targets\n",
        "\n",
        "    y_hat = self.net(y)\n",
        "    mean_loss = self.criterion(y_hat, targets) # Asuuming reduction=\"mean\"\n",
        "\n",
        "    target_class = torch.max(targets, 1)[1]\n",
        "    predicted_class = torch.max(y_hat, 1)[1] # Argmax gives predicted_class\n",
        "\n",
        "    num_errors = len(torch.nonzero(predicted_class - target_class))\n",
        "\n",
        "\n",
        "    return mean_loss, num_errors\n",
        "\n",
        "\n",
        "  def train_me(self, logs=True):\n",
        "    \"\"\"\n",
        "      Train the neural network for  max_epoch and print training and testing statistics.\n",
        "    \"\"\"\n",
        "\n",
        "    samples_len = self.testset.data.shape[0]\n",
        "    for i in range(self.max_epoch):\n",
        "      epoch = i + 1\n",
        "      train_loss = self.train_epoch()\n",
        "      test_loss, test_err = self.test_epoch()\n",
        "\n",
        "      if logs:\n",
        "        print(f\"Epoch: {epoch} | Train Loss: {train_loss:.04} |\"\n",
        "              f\"Test Loss: {test_loss:.04} | Test Error: {test_err/samples_len:.04}\")\n",
        "\n",
        "    return np.array([float(train_loss), float(test_loss)])\n",
        "\n",
        "\n",
        "def test_trainednetwork():\n",
        "  cifar_net = NeuralNetworkTrainer(\n",
        "      dataset_type=\"cifar\",\n",
        "      width=16,\n",
        "      depth=2,\n",
        "      criterion=nn.CrossEntropyLoss(),\n",
        "      optimizer=optim.Adam,\n",
        "      max_epoch=10\n",
        "  )\n",
        "\n",
        "  cifar_net.train_me()\n",
        "\n",
        "# Uncomment for network test\n",
        "# test_trainednetwork()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hyperparameter_scan(hyperparams, scan_param, param_range):\n",
        "\n",
        "  errors = {}\n",
        "  for e in param_range:\n",
        "\n",
        "      hyperparams[scan_param] = e\n",
        "      mnist_net = NeuralNetworkTrainer(**hyperparams)\n",
        "\n",
        "      errors[e] = mnist_net.train_me(logs=False)\n",
        "  \n",
        "  return errors\n",
        "\n",
        "\n",
        "def plot_errors(errors, xval, title, xlabel):\n",
        "  plt.title(title)\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.ylabel(\"Loss\")\n",
        "\n",
        "  train_error = [errors[e][0] for e in xval]\n",
        "  test_error = [errors[e][1] for e in xval]\n",
        "  plt.plot(xval, train_error, label=\"train loss\")\n",
        "  plt.plot(xval, test_error, label=\"test loss\")\n",
        "  \n",
        "  plt.legend()\n",
        "  plt.grid\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHBQTtwc2sVd"
      },
      "source": [
        "***\n",
        "\n",
        "### Part 3.2: Numerical exploration [2 points]\n",
        "\n",
        "#### Task 6 - Deep Networks Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finding max epoch\n",
        "\n",
        "In order to find an epoch for convergence, we will fix the below hyperparameters and calculate the loss for each epoch.\n",
        "\n",
        "| Hyperparameter | Fixed Value |\n",
        "|---|---|\n",
        "| `width` | 150 |\n",
        "| `depth` | 5 |\n",
        "| `criterion` | nn.CrossEntropyLoss() |\n",
        "| `optimizer` | optim.Adam |\n",
        "| `batch_size` | 64 |\n",
        "| `lr` | 0.001 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uxo1nGW9Heys"
      },
      "outputs": [],
      "source": [
        "hyperparams = {\n",
        "    \"dataset_type\": \"mnist\",\n",
        "    \"width\": 150,\n",
        "    \"depth\": 5,\n",
        "    \"criterion\": nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": optim.Adam,\n",
        "    \"batch_size\": 64,\n",
        "    \"lr\": 0.001,\n",
        "    \"normalize\": True\n",
        "}\n",
        "\n",
        "def max_epoch_finder(hyperparams, num_epochs):\n",
        "\n",
        "  errors = {}\n",
        "  for e in num_epochs:\n",
        "\n",
        "      hyperparams[\"max_epoch\"] = e\n",
        "      mnist_net = NeuralNetworkTrainer(**hyperparams)\n",
        "\n",
        "      errors[e] = mnist_net.train_me(logs=False)\n",
        "  \n",
        "  return errors\n",
        "\n",
        "#Uncomment for epoch optimisition:\n",
        "num_epochs = range(1, 36, 5)\n",
        "errors = max_epoch_finder(hyperparams, num_epochs)\n",
        "plot_errors(errors, num_epochs, \"MNIST Epoch vs Depth\", \"epochs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaI5aWvN06EL"
      },
      "source": [
        "#### Task 6 - Deep Networks Analysis\n",
        "\n",
        "Using the epoch fit for convergence that we found earlier, we are going to fix the below hyperparameters, and test different depths.\n",
        "\n",
        "| Hyperparameter | Fixed Value |\n",
        "|---|---|\n",
        "| `width` | 256 |\n",
        "| `criterion` | nn.CrossEntropyLoss() |\n",
        "| `optimizer` | optim.Adam |\n",
        "| `batch_size` | 64 |\n",
        "| `lr` | 0.001 |\n",
        "| `max_epoch` | 15 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzaGGVnT2sVn",
        "outputId": "65e666c5-e0eb-4228-9294-3677c4f5f697"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-e6f0142d11a9>:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.data = torch.tensor(self.data, dtype=torch.float32)            # Casting to float to prevent future problems.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Width: 4 | Train Loss: 1.086 | Test Loss: 1.073\n",
            "Width: 8 | Train Loss: 0.6269 | Test Loss: 0.6096\n",
            "Width: 16 | Train Loss: 0.4275 | Test Loss: 0.4223\n",
            "Width: 32 | Train Loss: 0.3448 | Test Loss: 0.3386\n",
            "Width: 64 | Train Loss: 0.309 | Test Loss: 0.3105\n",
            "Width: 128 | Train Loss: 0.2734 | Test Loss: 0.2795\n",
            "Width: 256 | Train Loss: 0.2283 | Test Loss: 0.2363\n",
            "Width: 512 | Train Loss: 0.1956 | Test Loss: 0.2132\n",
            "Width: 1024 | Train Loss: 0.1733 | Test Loss: 0.1923\n"
          ]
        }
      ],
      "source": [
        "# Fixed Hyperparameters:\n",
        "hyperparams = {\n",
        "    \"dataset_type\": \"mnist\",\n",
        "    \"width\": 256,\n",
        "    \"criterion\": nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": optim.Adam,\n",
        "    \"batch_size\": 64,\n",
        "    \"lr\": 0.001,\n",
        "    \"max_epoch\": 12,\n",
        "    \"normalize\": True\n",
        "}\n",
        "\n",
        "# Uncomment for test depths analysis:\n",
        "depths = range(1, 11)\n",
        "errors = hyperparameter_scan(hyperparams, \"depth\", depths)\n",
        "plot_errors(errors, depths, \"MNIST Loss vs Depth\", \"Depth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Task 7 - Wide Networks Analysis\n",
        "\n",
        "##### Depth analysis\n",
        "\n",
        "Using the epoch fit for convergence that we found earlier, we are going to fix the below hyperparameters, and test different widthes.\n",
        "\n",
        "| Hyperparameter | Fixed Value |\n",
        "|---|---|\n",
        "| `depth` | 1 |\n",
        "| `criterion` | nn.CrossEntropyLoss() |\n",
        "| `optimizer` | optim.Adam |\n",
        "| `batch_size` | 64 |\n",
        "| `lr` | 0.001 |\n",
        "| `max_epoch` | 10 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fixed Hyperparameters:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m hyperparams \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(),\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: optim\u001b[38;5;241m.\u001b[39mAdam,\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.001\u001b[39m,\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalize\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     11\u001b[0m }\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Uncomment for width analysis:\u001b[39;00m\n\u001b[0;32m     15\u001b[0m widths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m11\u001b[39m)]\n",
            "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ],
      "source": [
        "# Fixed Hyperparameters:\n",
        "hyperparams = {\n",
        "    \"dataset_type\": \"mnist\",\n",
        "    \"depth\": 1,\n",
        "    \"criterion\": nn.CrossEntropyLoss(),\n",
        "    \"optimizer\": optim.Adam,\n",
        "    \"batch_size\": 64,\n",
        "    \"lr\": 0.001,\n",
        "    \"max_epoch\": 10,\n",
        "    \"normalize\": True\n",
        "}\n",
        "\n",
        "\n",
        "# Uncomment for width analysis:\n",
        "widths = [2 ** i for i in range(2, 11)]\n",
        "errors = hyperparameter_scan(hyperparams, \"width\", widths)\n",
        "plot_errors(errors, widths, \"MNIST Loss vs Width\", \"Width\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMDhdlAQ2sVn"
      },
      "source": [
        "***\n",
        "***\n",
        "\n",
        "## Part 4: The link between Neural Networks and Gaussian Processes [8 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyCTq6XN2sVo"
      },
      "source": [
        "### Part 4.1: Proving the relationship between a Gaussian process and a neural network [4 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul5rk0ff2sVo"
      },
      "source": [
        "### Task 1: Proper weight scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NV1eU6d2sVo"
      },
      "source": [
        "The scaling makes sense because we want to employ the Central Limit Theorm on $f_i^{(2)}(x)$. CLT states that the sum of $N$ i.i.d r.v. $X_i, ... ,X_N $ with mean and variance $\\mu, \\sigma^2$ distributes (approx.) as $\\mathcal{N}(N \\mu, N \\sigma^2)$. In our case, the mean $\\mathbb{E}[f_i^{(2)}]=0$ and the variance depends on the variance of the wieghts $w_{ij}^{(2)}$ (more details below). Then, in order to keep the variance from diverging as $N_1 \\rightarrow \\infty$ and apply CLT, we have to normalize the variance of the wieghts by $N_1$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOdoN0OQ2sVo"
      },
      "source": [
        "### Task 2: Derive the GP relation for a single hidden layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoIW9iH_2sVo"
      },
      "source": [
        "We will use similar notation to [Matthews et al., 2018]. Consider two inputs $x, x'$, and define the vector $\\boldsymbol{f}^{(2)}(x)$ with elements $f^{(2)}_i(x)\\, , i=1,...,N_2$. Then we define the vector $\\boldsymbol{F}^{(2)}$ with length $2N_2$ as the concatenation of $\\boldsymbol{f}^{(2)}(x), \\boldsymbol{f}^{(2)}(x')$:\n",
        "\n",
        "$$\n",
        "\\boldsymbol{F}^{(2)} = \\begin{pmatrix} \\boldsymbol{f}^{(2)}(x) \\\\ \\boldsymbol{f}^{(2)}(x') \\end{pmatrix} = \\begin{pmatrix} \\boldsymbol{b}^{(2)} \\\\ \\boldsymbol{b}^{(2)} \\end{pmatrix} + ∑_{j=1}^{N_1} \\begin{pmatrix} w^{(2)}_{:, j}g_j^{(1)}(x) \\\\ w^{(2)}_{:, j}g_j^{(1)}(x') \\end{pmatrix}\n",
        "$$\n",
        "\n",
        "where the sum over $w^{(2)}_{:, j}$ means that it applies for every neuron in the vector $1 \\le i \\le N_{1}$.\n",
        "\n",
        "Now, in order to apply multivariate CLT we want to show that the terms in the sum are i.i.d from each other. For each $l$, $w_{ij}^{(l)}$ are drawn from the same distribution, hence they are i.i.d. The post activations for layer 1 $g_j^{(1)}$, are functions of $w_{ij}^{(1)}, b_j^{(1)}$, hence they too are i.i.d. Therefore, the sum is over i.i.d vectors, and we can apply multivariate CLT.\n",
        "Also, the mean is zero and we normalized the variance, so the variance does not diverge with the limit (as explained above). \n",
        "\n",
        "To find the limit distribution after multivariate CLT we calculate we use linearity of expectetion and independence,\n",
        "$$\n",
        "\\mathbb{E}[f_i^{(2)}(x)]= ∑_i^{N_1}\\mathbb{E}[w_{i,j}^{(2)}g_j^{(1)}(x)] + \\mathbb{E}[b_i^{(2)}]= ∑_i^{N_1} 0 \\cdot \\mathbb{E}[g_j^{1}(x)] + 0 = 0\\, ,\n",
        "$$\n",
        "\n",
        "so $\\mu^1 = \\boldsymbol{0}$ .\n",
        "\n",
        "The covariance matrix denoted by $K^1$ would be given by:\n",
        "$$\n",
        "K^1_{i,j} (x, x') = \\mathbb{E} \\left[ (f_i^{(2)(x)} - \\mathbb{E}[f_i^{(2)}(x)]) ⋅ (f_j^{(2)(x')} - \\mathbb{E}[f_j^{(2)}(x')]) \\right] = \\mathbb{E} \\left[ (f_i^{(2)}(x)) ⋅ (f_j^{(2)}(x')) \\right] \\, .\n",
        "$$\n",
        "\n",
        "If $i \\ne j$ then independence gives us\n",
        "$$\n",
        "\\mathbb{E} \\left[ (f_i^{(2)}(x)) ⋅ (f_j^{(2)}(x')) \\right] = \\mathbb{E} \\left[ f_i^{(2)}(x) \\right] \\mathbb{E} \\left[ f_j^{(2)}(x') \\right] = 0 \\; .\n",
        "$$\n",
        "so we are left with the diagonal elements. Further calculations of this expression are done in the general $L$ hidden layers below.\n",
        "\n",
        "Finally, multivariate CLT gives:\n",
        "$$\n",
        "\\boldsymbol{F}^{(2)} \\xrightarrow{N_1 \\rightarrow ∞} \\mathcal{N}(\\boldsymbol{0}, K^1(x, x'))\\, ,\n",
        "$$\n",
        "\n",
        "which means that the limiting distribution is a $\\mathcal{GP}$ with respect to the inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbxrzInZ2sVo"
      },
      "source": [
        "### Task 3: Why in succession"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oRi0kiP2sVo"
      },
      "source": [
        "The proof of the whole network is done by induction, and the inductive hypothesis is that layer $l-1$ is a $\\mathcal{GP}$ when $N_{l-1} \\to \\infty$. Therefore, the hidden layer widths are taken to infinite in succession, because when we show that level $l$ is a $\\mathcal{GP}$, we use the fact that level $l-1$ is a $\\mathcal{GP}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBiy5sKA2sVo"
      },
      "source": [
        "### Task 4: Derive the GP relation for multiple hidden layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaIEL1AK2sVo"
      },
      "source": [
        "The proof is similar to the 1 hidden layer case (induction base). Assume that $f_j^{l-1}$ is a $\\mathcal{GP}$ over the inputs, hence both $f_j^{l-1}$ and the post activations $g_j^{l-1}$ are i.i.d.\n",
        "\n",
        "The output to the $i$'th neuron on layer $l$ is\n",
        "\n",
        "$$\n",
        "f_i^{(l)} (x) = \\sum^{N_l}_{j=1} w^{(l)}_{ij} g^{(l-1)}_{j}(x) + b^{(l)}_{j} \\; .\n",
        "$$\n",
        "\n",
        "and we can construct\n",
        "\n",
        "$$\n",
        "\\boldsymbol{F}^{(l)} = \\begin{pmatrix} \\boldsymbol{f}^{(l)}(x) \\\\ \\boldsymbol{f}^{(l)}(x') \\end{pmatrix} = \\begin{pmatrix} \\boldsymbol{b}^{(l)} \\\\ \\boldsymbol{b}^{(l)} \\end{pmatrix} + ∑_{j=1}^{N_l} \\begin{pmatrix} w^{(l)}_{:, j}g_j^{(l-1)}(x) \\\\ w^{(l)}_{:, j}g_j^{(l-1)}(x') \\end{pmatrix} \\; .\n",
        "$$\n",
        "\n",
        "Again, the sum is over i.i.d. variables with mean zero and variance normalized by $N_l$, then we can apply CLT.\n",
        "\n",
        "**Note**: to explicitly use the formal definition of CLT, we can represent $w^{(l)}_{i, j} = \\frac{1}{\\sqrt{N_l}} X_{ij}^{(l)}$ where $X_{ij}^{(l)} \\sim \\mathcal{N}(0, \\sigma_w^{(l)})$. Then the sum over $w$ becomes $S_{N_l} = \\frac{1}{\\sqrt{N_l}} \\sum_{j=1}^{N_l}X_{ij}^{(l)} \\to \\mathcal{N}(0, K^l), \\; N_l \\to \\infty$ where we used the fact the $\\mathbb{E}(X_{ij}^{(l)})=0$.\n",
        "\n",
        "The limit distribution of $\\boldsymbol{F}^{(l)}$:\n",
        "\n",
        "$$\n",
        "\\mu^{l-1} = \\mathbb{E}[f_i^{(l)}(x)]= ∑_i^{N_1}\\mathbb{E}[w_{i,j}^{(l)}g_j^{(l-1)}(x)] + \\mathbb{E}[b_i^{(l)}]= ∑_i^{N_1} 0 \\cdot \\mathbb{E}[g_j^{l-1}(x)] + 0 = 0\\, ,\n",
        "$$\n",
        "\n",
        "$$\n",
        "K^{l-1}_{i,j} (x, x') = \\mathbb{E} \\left[ (f_i^{(l)}(x) - \\mathbb{E}[f_i^{(l)}(x)]) ⋅ (f_j^{(l)(x')} - \\mathbb{E}[f_j^{(l)}(x')]) \\right] = \\mathbb{E} \\left[ (f_i^{(l)}(x)) ⋅ (f_j^{(l)}(x')) \\right] \\; ,\n",
        "$$\n",
        "if $i \\ne j$ then by the mentioned independence $K^{l-1}_{i,j} (x, x') = \\mathbb{E} [ f_i^{(l)}(x)] \\mathbb{E} [f_j^{(l)}(x')] = 0$. Otherwise,\n",
        "\n",
        "Else,\n",
        "$$\n",
        "\\mathbb{E} \\left[ (f_i^{(l)}(x)) ⋅ (f_i^{(l)}(x')) \\right] = \\mathbb{E} \\left[ \\left( ∑_j w_{i,j}^{(l)}g_j^{(l-1)}(x) + b_i^{(l)} \\right) \\left( ∑_j w_{i,j}^{(l)}g_j^{(l-1)}(x') + b_i^{(l)} \\right) \\right] \\; .\n",
        "$$\n",
        "Opening this expression gives and using linearity we find two sums that have zero expectation (since the bias is independent and have zero mean), one double sum, and $\\mathbb{E}[b_i^2] = \\sigma_b^{(2)}$. The double sum is:\n",
        "\n",
        "$$\n",
        "\\mathbb{E} \\left[ \\sum_{k=1} \\sum_{k=1} w_{ik}^{(l)}g_{k}^{l-1}(x) w_{ij}^{(l)}g_{j}^{(l-1)}(x')  \\right] = \\mathbb{E} \\left[ (w_{ii}^{(l)}) ^2 g_{i}^{l-1}(x)g_{j}^{(l-1)}(x')  \\right] = (\\sigma_w ^{(l)})^2 \\mathbb{E} \\left[ g_{i}^{l-1}(x)g_{j}^{(l-1)}(x')  \\right]\n",
        "$$\n",
        "where again we used linearity of expectation, independece of the weights, and zero mean for the weights.\n",
        "\n",
        "Finally, we find\n",
        "$$\n",
        "\\mu^{l-1} = 0 \\\\\n",
        "K^{l-1}_{i,j} (x, x') = (\\sigma _b ^{(l)}) ^2 + (\\sigma_w ^{(l)})^2 \\mathbb{E} \\left[ g_{i}^{l-1}(x)g_{j}^{(l-1)}(x')  \\right]\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\boldsymbol{F}^{(l)} \\xrightarrow{N_{l-1} \\rightarrow ∞} \\mathcal{N} \\left( \\boldsymbol{0}, K^{l-1}(x, x') \\right) \\, ,\n",
        "$$\n",
        "\n",
        "where we have to remember that in this notation $K^{l-1}$ is the kernel for layer $l$ (as $K^1$ was defined the kernel for layer 2).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNzWgsXt2sVo"
      },
      "source": [
        "***\n",
        "\n",
        "### Part 4.2: Analysing the performance of the Gaussian process and a neural network [4 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unW1bYqJ2sVo"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FppSzjEZ2sVo"
      },
      "outputs": [],
      "source": [
        "# Please use float64 as default dtype for this part of the assignment\n",
        "torch.set_default_dtype(torch.float64)\n",
        "\n",
        "# Another hint: when  computing [ K^L(X,X) + noise^2 Id ]^-1 y and  [ K^L(X,X) + noise^2 Id ]^-1 K^L(X,X*)\n",
        "# You can TRY cholesky solve as it should be p.d. (except case for numerical errors) - maybe you can use try:/except:\n",
        "# You can also try to enforce symmetry in posterior covariance by doing (K + K.t())/2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Task 0 - Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "z_c3V9YH2sVp"
      },
      "outputs": [],
      "source": [
        "class CifarGpDataset(ImageDataset):\n",
        "    def __init__(self, train: bool, normalize: bool):\n",
        "      self.labels = [0, 1]\n",
        "      super().__init__(\"cifar\", train, normalize, 2)\n",
        "\n",
        "    def _create_data(self, raw_targets):\n",
        "      raw_targets = torch.tensor(raw_targets, dtype=torch.float64)\n",
        "      self.data = torch.tensor(self.data, dtype=torch.float64)\n",
        "      self.data = self.data[(raw_targets==1) | (raw_targets == 2), :]\n",
        "\n",
        "\n",
        "    def _create_targets(self, raw_targets, nclasses):\n",
        "      raw_targets = torch.tensor(raw_targets, dtype=torch.float64)\n",
        "      self.targets = raw_targets[(raw_targets==1) | (raw_targets == 2)]\n",
        "      self.targets[self.targets==1] *= 0.5\n",
        "      self.targets[self.targets==2] *= -1/4\n",
        "\n",
        "# Uncomment to test the data and targets filtration\n",
        "# dataset = CifarGpDataset(True, True)\n",
        "# dataset.data.shape[0] == dataset.targets.shape[0]\n",
        "# print(dataset.targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Task 1 - GP Kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GpKernal:\n",
        "  def __init__(self, L, var_w, var_b):\n",
        "    self.L = L\n",
        "    self.sigma_b = torch.sqrt(var_b)\n",
        "    self.sigma_w = torch.sqrt(var_w)\n",
        "\n",
        "  def kernal(self, l, X1, X2):\n",
        "\n",
        "\n",
        "    sigma_b = self.sigma_b\n",
        "    sigma_w = self.sigma_w\n",
        "\n",
        "    if not l:\n",
        "      N0 = X1.shape[0]\n",
        "      return sigma_b + sigma_w * (X1 @ X2.T)/N0\n",
        "\n",
        "    k11 = self.kernal(l-1, X1, X1)\n",
        "    k22 = self.kernal(l-1, X2, X2)\n",
        "    k12 = self.kernal(l-1, X1, X2)\n",
        "    \n",
        "    diag1 = torch.diagonal(k11, 0) # All we need for computation is the diagonal!\n",
        "    diag2 = torch.diagonal(k22, 0)\n",
        "\n",
        "    k_mult= diag1.unsqueeze(1) @ diag2.unsqueeze(0) # Making two vector-matricies and multiply to get (M1 x M2) matrix.\n",
        "    clipped_arg = torch.clamp(k12 / torch.sqrt( k_mult ), -1., 1.)\n",
        "    theta = torch.acos(clipped_arg)\n",
        "\n",
        "    if torch.any(torch.isnan(theta)):\n",
        "      print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!1\")\n",
        "\n",
        "\n",
        "    res = sigma_b + sigma_w/(2*torch.pi) * torch.sqrt(k_mult) * (torch.sin(theta) + (torch.pi - theta)*torch.cos(theta))\n",
        "    \n",
        "    return res\n",
        "\n",
        "  def __call__(self, X1, X2):\n",
        "    \"\"\"\n",
        "    X1: M1 x N0\n",
        "    X2: M2 x N0\n",
        "    N0 = dimension of input\n",
        "    M1, M2 - amount of datapoints in X1, X2\n",
        "\n",
        "    k_11: M1 x M1\n",
        "    k_22: M2 x M2\n",
        "    k_12: M1 x M2\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    if X1.shape[1] != X2.shape[1]:\n",
        "      raise ValueError(\"X1 and X2 must have same dimension along axis 1\")\n",
        "\n",
        "    return self.kernal(self.L, X1, X2)\n",
        "\n",
        "#test1\n",
        "# my_kernal = GpKernal(5, torch.tensor(0.1), torch.tensor(0.1))\n",
        "# X1 = 50*torch.randn((5, 10))\n",
        "# X2 = torch.randn((7, 10))\n",
        "# for i in range(5):\n",
        "#   print(my_kernal.kernal(i, X1, X2))\n",
        "\n",
        "# test2\n",
        "my_kernal = GpKernal(5, torch.tensor(0.1), torch.tensor(0.1))\n",
        "X1 = 50*torch.randn((5, 10))\n",
        "X2 = torch.randn((7, 10))\n",
        "a = my_kernal(X1, X2)\n",
        "print(a, a.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Task 2 - Posterior Mean and Cov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CifarGaussianProcess:\n",
        "    def __init__(self, var_b, var_w, sigma, L, test_samples=1000, train_samples=1000):\n",
        "        self.var_b = var_b\n",
        "        self.var_w = var_w\n",
        "        self.sigma = sigma\n",
        "        self.L = L\n",
        "\n",
        "        self.k = GpKernal(L, var_w, var_b)\n",
        "\n",
        "        train_set = CifarGpDataset(True, True)    # train set\n",
        "        test_set = CifarGpDataset(False, True)    # test points\n",
        "\n",
        "        self.X, self.y = train_set.data[:train_samples], train_set.targets[:train_samples]\n",
        "        self.x_star, self.targets = test_set.data[:test_samples], test_set.targets[:test_samples]\n",
        "\n",
        "        self.X = torch.flatten(self.X, start_dim=1)\n",
        "        self.x_star = torch.flatten(self.x_star, start_dim=1) \n",
        "\n",
        "    def _compute_posterior(self):\n",
        "        k_x_x = self.k(self.X, self.X)            \n",
        "        k_xs_xs = self.k(self.x_star, self.x_star) \n",
        "        k_xs_x = self.k(self.x_star, self.X)       \n",
        "        k_x_xs = k_xs_x.T           \n",
        "        cov_x_x = k_x_x + self.sigma**2 * torch.eye(self.X.shape[0]).to(device=device)\n",
        "\n",
        "        cov_inverse_y = torch.linalg.solve(cov_x_x, self.y)\n",
        "        cov_inverse_k = torch.linalg.solve(cov_x_x, k_x_xs)\n",
        "\n",
        "        posterior_mean = torch.matmul(k_xs_x, cov_inverse_y)\n",
        "        posterior_var = k_xs_xs - torch.matmul(k_xs_x, cov_inverse_k)\n",
        "\n",
        "        posterior_var = (posterior_var + posterior_var.T) / 2  # Enforce symmetry\n",
        "        # Add a small amount of noise to the diagonal to make the covariance matrix positive definite\n",
        "        posterior_var = posterior_var + 1e-6 * torch.eye(posterior_var.shape[0]).to(device=device)\n",
        "\n",
        "\n",
        "        return posterior_mean, posterior_var\n",
        "\n",
        "    def predict(self, size, contract=False):\n",
        "        mean, var = self._compute_posterior()\n",
        "        y_star = torch.distributions.MultivariateNormal(mean, var).sample((size,))\n",
        "\n",
        "        if contract:\n",
        "          y_star, targets = (y_star > 0).to(dtype=torch.float64), (self.targets > 0).to(dtype=torch.float64)\n",
        "          return torch.mean(y_star, 0), targets # fix sum shit here\n",
        "\n",
        "        return (y_star > 0).to(dtype=torch.float64), (self.targets > 0).to(dtype=torch.float64)\n",
        "\n",
        "\n",
        "    def test_gaussian_process(self, posterior_mean, posterior_var, size, y_star):\n",
        "        y_predic = torch.distributions.MultivariateNormal(posterior_mean, posterior_var).sample((size,))\n",
        "        y_predic = y_predic.mean(0)\n",
        "        y_predic = (y_predic > 0).to(torch.float32)\n",
        "\n",
        "        test_result = torch.abs(y_star - y_predic).sum() / self.N\n",
        "        return test_result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gp_hyperparams = {\n",
        "    \"var_b\": torch.tensor(0.1),\n",
        "    \"var_w\": torch.tensor(0.1),\n",
        "    \"sigma\": torch.tensor(0.1),\n",
        "    \"L\": 4,\n",
        "    \"test_samples\": 1000,\n",
        "    \"train_samples\": 1500\n",
        "}\n",
        "\n",
        "gp = CifarGaussianProcess(**gp_hyperparams)\n",
        "y_star, targets = gp.predict(1, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "layers = range(1, 6)\n",
        "accuracy = []\n",
        "for i in layers:\n",
        "  gp_hyperparams[\"L\"] = i\n",
        "  gp = CifarGaussianProcess(**gp_hyperparams)\n",
        "  y_star, targets = gp.predict(1, False)\n",
        "  err = torch.abs(y_star[0] - targets[0]).sum()/1000\n",
        "  print(err)\n",
        "  accuracy.append(1 - torch.abs(y_star[0] - targets[0]).sum()/1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Refrences\n",
        "\n",
        "[Matthews et al., 2018] Matthews, A. G. d. G., Rowland, M., Hron, J., Turner,\n",
        "R. E., and Ghahramani, Z. (2018). Gaussian process behaviour in wide deep\n",
        "neural networks. arXiv preprint arXiv:1804.11271.\n",
        "\n",
        "[Lee et al., 2017] Lee, J., Bahri, Y., Novak, R., Schoenholz, S. S., Pennington, J.,\n",
        "and Sohl-Dickstein, J. (2017). Deep neural networks as gaussian processes. arXiv\n",
        "preprint arXiv:1711.00165.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
